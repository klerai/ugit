{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project UGIT - a Python based sample of a GIT type repository tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Processing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: base.py\n",
    "# Date: 2020-12-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "# import os\n",
    "import string\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from ugit import data\n",
    "from ugit import diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init ():\n",
    "    data.init ()\n",
    "    data.update_ref ('HEAD', data.RefValue (symbolic=True, \n",
    "                                            value='refs/heads/master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tree ():\n",
    "    \"\"\" Creating a 'tree' object from entries in the index Jason file \n",
    "    and storing it into the object database \"\"\"\n",
    "\n",
    "    # Index is flat, we need it as a tree of dictionaries\n",
    "    index_as_tree = {}\n",
    "    with data.get_index () as index:\n",
    "        for f_path, oid in index.items ():\n",
    "            f_path = f_path.split ('/')\n",
    "            dirpath, filename = f_path[:-1], f_path[-1]\n",
    "            \n",
    "            current = index_as_tree\n",
    "            # Find the dict for the directory of this file\n",
    "            for dirname in dirpath:\n",
    "                current = current.setdefault (dirname, {})\n",
    "            current[filename] = oid\n",
    "            \n",
    "    def write_tree_recursive (tree_dict):\n",
    "        entries = []\n",
    "        for name, value in tree_dict.items ():\n",
    "            if type (value) is dict:\n",
    "                type_ = 'tree'\n",
    "                oid = write_tree_recursive (value)\n",
    "            else:\n",
    "                type_ = 'blob'\n",
    "                oid = value\n",
    "            entries.append ((name, oid, type_))\n",
    "            \n",
    "        tree = ''.join (f'{type_} {oid} {name}\\n'\n",
    "                        for name, oid, type_\n",
    "                        in sorted (entries))\n",
    "        return data.hash_object (tree.encode (), 'tree')\n",
    "    \n",
    "    return write_tree_recursive (index_as_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iter_tree_entries (oid):\n",
    "    \"\"\"Using a generator to fetch the tree file by OID\n",
    "    and for each line in the file we return: type_, oid, filepath\n",
    "    \"\"\"\n",
    "    if not oid:\n",
    "        return ''\n",
    "    return (entry.split (' ', 2) \n",
    "            for entry in data.get_object (oid, 'tree').decode ().splitlines ())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree (oid, base_path=''):\n",
    "    result = {}\n",
    "    for type_, oid, name in _iter_tree_entries (oid):\n",
    "        assert '/' not in name\n",
    "        # assert name not in ('..', '.')\n",
    "        path = base_path + name\n",
    "        if type_ == 'blob':\n",
    "            result[path] = oid\n",
    "        elif type_ == 'tree':\n",
    "            result.update (get_tree (oid, f'{path}/'))\n",
    "        else:\n",
    "            assert False, f'Unknown tree entry {type_}'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_dir(directory: Path):\n",
    "    \"\"\" Scan directory tree for all valid files, and return\n",
    "    a dictionary with file_paths and OIDs.\n",
    "    Expects a Path object\n",
    "    Returns a dictionary with filepaths and their OIDs.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "   \n",
    "    for path in (fp for fp in directory.rglob ('*') \n",
    "               if not is_ignored (fp) and fp.is_file ()):\n",
    "        result [str(path)] = data.hash_object (path.read_bytes ())\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_working_tree ():\n",
    "    \"\"\" Return all files from the working tree as dictionary \"\"\"\n",
    "    return scan_dir(Path('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_tree ():\n",
    "    with data.get_index () as index:\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _empty_current_directory ():\n",
    "    \"\"\" Remove all files/directories of the current tree (unless is_ignored)\"\"\"\n",
    "    paths = []\n",
    "\n",
    "    # First removing all files...\n",
    "    for path in (fp for fp in Path('.').rglob ('*')\n",
    "               if not is_ignored (fp)):\n",
    "        if path.is_file ():\n",
    "            path.unlink ()\n",
    "        else:\n",
    "            paths.append(path)\n",
    "            \n",
    "    # then removing all directories...\n",
    "    paths.sort (reverse=True)\n",
    "    for path in paths:\n",
    "        path.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _checkout_index (index):\n",
    "    \"\"\"For every entry in the index, the respected object is copied to the given\n",
    "    file path. Any missing directory structure is created during the process.\n",
    "    \"\"\"\n",
    "    _empty_current_directory ()\n",
    "    for path, oid in index.items ():\n",
    "        fp = Path(path)\n",
    "        if not fp.parent.is_dir():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fp.write_bytes(data.get_object (oid, 'blob'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree (tree_oid, update_working=False):\n",
    "    \"\"\" Read tree object from the database to the index file, \n",
    "    and checkout the files into the working directory.\n",
    "    \"\"\"\n",
    "    with data.get_index () as index:\n",
    "        index.clear ()\n",
    "        index.update (get_tree (tree_oid))\n",
    "        \n",
    "        if update_working:\n",
    "            _checkout_index (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree_merged (t_base, t_HEAD, t_other, update_working=False):\n",
    "    with data.get_index () as index:\n",
    "        index.clear ()\n",
    "        index.update (diff.merge_trees (\n",
    "            get_tree (t_base),\n",
    "            get_tree (t_HEAD),\n",
    "            get_tree (t_other)\n",
    "        ))\n",
    "        \n",
    "        if update_working:\n",
    "            _checkout_index (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit (message):\n",
    "    \"\"\" Save commit object to the database \n",
    "    and adjust HEAD and references accordingly\n",
    "    \"\"\"\n",
    "    # Record hash of last commit to HEAD\n",
    "    commit = f'tree {write_tree ()}\\n'\n",
    "\n",
    "    HEAD = data.get_ref ('HEAD').value\n",
    "    if HEAD:\n",
    "        commit += f'parent {HEAD}\\n'\n",
    "    MERGE_HEAD = data.get_ref ('MERGE_HEAD').value\n",
    "    if MERGE_HEAD:\n",
    "        commit += f'parent {MERGE_HEAD}\\n'\n",
    "        data.delete_ref ('MERGE_HEAD', deref=False)\n",
    "        \n",
    "    commit += '\\n'\n",
    "    commit += f'{message}\\n'\n",
    "\n",
    "    oid = data.hash_object (commit.encode (), 'commit')\n",
    "    \n",
    "    data.update_ref ('HEAD', data.RefValue (symbolic=False, value=oid))\n",
    "        \n",
    "    return oid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkout (name):\n",
    "    \"\"\" Reset the working directory to the given TAG/BRANCH/OID \n",
    "    and move the HEAD to this OID\n",
    "    \"\"\"\n",
    "    # Read tree and move HEAD\n",
    "    oid = get_oid (name)\n",
    "    commit = get_commit (oid)\n",
    "    read_tree (commit.tree, update_working=True)\n",
    "    \n",
    "    if is_branch (name):\n",
    "        HEAD = data.RefValue (symbolic=True, value=f'refs/heads/{name}')\n",
    "    else:\n",
    "        HEAD = data.RefValue (symbolic=False, value=oid)\n",
    "    \n",
    "    data.update_ref ('HEAD', HEAD, deref=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset (oid):\n",
    "    \"\"\" Resetting the HEAD to a given OID, is like undo all newer commits \"\"\"\n",
    "    data.update_ref ('HEAD', data.RefValue (symbolic=False, value=oid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge (other):\n",
    "    # Merge heads together\n",
    "    HEAD = data.get_ref ('HEAD').value\n",
    "    assert HEAD\n",
    "    merge_base = get_merge_base (other, HEAD)\n",
    "    c_other = get_commit (other)\n",
    "\n",
    "    # Handle fast-forward merge\n",
    "    if merge_base == HEAD:\n",
    "        read_tree (c_other.tree, update_working=True)\n",
    "        data.update_ref ('HEAD',\n",
    "                         data.RefValue (symbolic=False, value=other))\n",
    "        print ('Fast-forward merge, no need to commit')\n",
    "        return\n",
    "    \n",
    "    data.update_ref ('MERGE_HEAD', data.RefValue (symbolic=False, value=other))\n",
    "    \n",
    "    c_base = get_commit (merge_base)\n",
    "    c_HEAD = get_commit (HEAD)\n",
    "    read_tree_merged (c_base.tree, c_HEAD.tree, c_other.tree, update_working=True)\n",
    "    print ('Merged in working tree\\nPlease commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_base (oid1, oid2):\n",
    "    parents1 = list (iter_commits_and_parents ({oid1}))\n",
    "    \n",
    "    for oid in iter_commits_and_parents ({oid2}):\n",
    "        if oid in parents1:\n",
    "            return oid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ancestor_of (commit, maybe_ancestor):\n",
    "    return maybe_ancestor in iter_commits_and_parents ({commit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag (name, oid):\n",
    "    \"\"\" Creating a tag object pointing to the given OID \"\"\"\n",
    "    data.update_ref (f'refs/tags/{name}', data.RefValue (symbolic=False, value=oid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_branch (name, oid):\n",
    "    \"\"\" Creating a branch object pointing to the given OID \"\"\"\n",
    "    data.update_ref (f'refs/heads/{name}', data.RefValue (symbolic=False, value=oid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_branch (branch):\n",
    "    return data.get_ref (f'refs/heads/{branch}').value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch_name ():\n",
    "    HEAD = data.get_ref ('HEAD', deref=False)\n",
    "    if not HEAD.symbolic:\n",
    "        return None\n",
    "    HEAD = HEAD.value\n",
    "    assert HEAD.startswith ('refs/heads/')\n",
    "    return HEAD.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commit = namedtuple ('Commit', ['tree', 'parents', 'message'])\n",
    "RefValue.__doc__ = \"\"\"A name tuple representing a commit value\n",
    "- with three fields:\n",
    "  tree     - Object Id\n",
    "  parents  - Object Id\n",
    "  message  - associated text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit (oid):\n",
    "    parents = []\n",
    "    \n",
    "    commit = data.get_object (oid, 'commit').decode ()\n",
    "    lines = iter (commit.splitlines ())\n",
    "    for line in itertools.takewhile (operator.truth, lines):\n",
    "        key, value = line.split (' ', 1)\n",
    "        if key == 'tree':\n",
    "            tree = value\n",
    "        elif key == 'parent':\n",
    "            parents.append (value)\n",
    "        else:\n",
    "            assert False, f'Unknown field {key}'\n",
    "    \n",
    "    message = '\\n'.join (lines)\n",
    "    return Commit (tree=tree, parents=parents, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_commits_and_parents (oids):\n",
    "    # N.B. Must yield the oid before accessing it.\n",
    "    #      To allow caller to fetch it if needed)\n",
    "    oids = deque (set (oids))\n",
    "    visited = set ()\n",
    "    \n",
    "    while oids:\n",
    "        oid = oids.popleft ()\n",
    "        if not oid or oid in visited:\n",
    "            continue\n",
    "        visited.add (oid)\n",
    "        yield oid\n",
    "        \n",
    "        commit = get_commit (oid)\n",
    "        # Return first parent next\n",
    "        oids.extendleft (commit.parents[:1])\n",
    "        # Return other parents later\n",
    "        oids.extend (commit.parents[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_objects_in_commits (oids):\n",
    "    # N.B. Must yield the oid before accessing it.\n",
    "    #      To allow caller to fetch it if needed)\n",
    "    visited = set ()\n",
    "    \n",
    "    def iter_objects_in_tree (oid):\n",
    "        visited.add (oid)\n",
    "        yield oid\n",
    "        for type_, oid, _ in _iter_tree_entries (oid):\n",
    "            if oid not in visited:\n",
    "                if type_ == 'tree':\n",
    "                    yield from iter_objects_in_tree (oid)\n",
    "                else:\n",
    "                    visited.add (oid)\n",
    "                    yield oid\n",
    "    \n",
    "    for oid in iter_commits_and_parents (oids):\n",
    "        yield oid\n",
    "        commit = get_commit (oid)\n",
    "        if commit.tree not in visited:\n",
    "            yield from iter_objects_in_tree (commit.tree)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oid (name):\n",
    "    \"\"\" Return oid for a given reference \"\"\"\n",
    "    if name == '@': name = 'HEAD'\n",
    "    \n",
    "    # Name is ref\n",
    "    refs_to_try = [\n",
    "        f'{name}',\n",
    "        f'refs/{name}',\n",
    "        f'refs/tags/{name}',\n",
    "        f'refs/heads/{name}',\n",
    "    ]\n",
    "    for ref in refs_to_try:\n",
    "        if data.get_ref (ref, deref=False).value:\n",
    "            return data.get_ref (ref).value\n",
    "\n",
    "    # Name is SHA1\n",
    "    is_hex = all (c in string.hexdigits for c in name)\n",
    "    if len (name) == 40 and is_hex:\n",
    "        return name\n",
    "\n",
    "    assert False, f'Unknown name {name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add (filenames: list):\n",
    "    \"\"\" \n",
    "    Add one or more files/directories to the Index file\n",
    "        Expects as list of 'filepaths' \n",
    "    \"\"\"\n",
    "    with data.get_index () as index:\n",
    "        for file_path in filenames:\n",
    "            if is_ignored(file_path):\n",
    "                continue\n",
    "            elif file_path.is_file():\n",
    "                \"\"\" add file/hash for specified file \"\"\"\n",
    "                index[str(file_path)] = data.hash_object(file_path.read_bytes())\n",
    "            elif file_path.is_dir():\n",
    "                \"\"\" Add dictionary of files/hashes within specified path\"\"\"\n",
    "                index.update(**scan_dir(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ignored (path):\n",
    "    if '__pycache__' in path.parts:        \n",
    "        return False\n",
    "    \n",
    "    if path.suffix == '.ipynb':\n",
    "        return True\n",
    "    \n",
    "    for s in ['.ipynb_checkpoints', '.gitignore', '.ugit', 'p.ugit', 'o.ugit', 'ugit.egg-info']:\n",
    "        if s in path.parts:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "    # orig: return '.ugit' in path.parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Testing routines for base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TEST: Fetching current HEAD's OID:\n",
      "f0ed05c972c1336315641d3cabd6169bb8b9b2c1\n",
      "\n",
      " - and retrieving it's commit record:\n",
      "Commit(tree='992bcf6e9e337d4fb01e9adedbead7755ab41ddf', parents=['a5b1ef8fabf605b1a50b88c17a87f7440f662bd6'], message='Working directory is prepared')\n",
      "\n",
      " - followed by the tree object with list of files\n",
      "{'WorkNotes.txt': '52640e3e3a7f26dbbf38f78d5ae85936b9ed4866', 'setup.py': '2755dd23451d7d50751db5cacb3b059dc076989c', 'ugit/4tests/list_object_heads.py': 'bbb490717ee7274f8c1c4c7104d23a7e159419c4', 'ugit/4tests/ugit-test.py': '2b62fa7d22412ba4348f71b979b97bb747785b0c', 'ugit/__pycache__/base.cpython-36.pyc': '69603150f4ecdb5a811cc8fbbe53b93c1a65f2d4', 'ugit/__pycache__/data.cpython-36.pyc': '8791ff03518dca0f8521ba7d6dce987aeee58346', 'ugit/__pycache__/diff.cpython-36.pyc': 'b9ddb27dae2e6ed6396896e98d18388bb4c84512', 'ugit/base.py': '82d611a6bbf08c9a81f11ab00ab7da781dac4a9e', 'ugit/cli.py': 'b2838bba4356dcaad890f01028d95492ce22ee54', 'ugit/data.py': 'a434464f5e65b68695bd27fc1d29a8d18f927b8a', 'ugit/diff.py': '67ee81b8e3c4c94c2bc70d741f21dfb997a493c9', 'ugit/remote.py': '47aed01fb9e6d9774f65074d207481af4aa73161'}\n"
     ]
    }
   ],
   "source": [
    "#4TEST\n",
    "print (\"'TEST: Fetching current HEAD's OID:\")\n",
    "HEAD = get_oid ('@')\n",
    "print (HEAD)\n",
    "print ()\n",
    "print (\" - and retrieving it's commit record:\")\n",
    "c_HEAD = get_commit (HEAD)\n",
    "print (c_HEAD)\n",
    "print ()\n",
    "print (' - followed by the tree object with list of files')\n",
    "\n",
    "print (get_tree (c_HEAD[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4TEST \n",
    "# TODO we need to provide commit points dynamically\n",
    "print ('Testing Branching:')\n",
    "print (' - creating branch: v1.0')\n",
    "create_branch ('v0.1', '214b7934df75843918745fe64a9d2ebb45e3b3da')\n",
    "create_branch ('v1.0', '79c46baf2fe1879296399fbdd9472909ee01d1fe')\n",
    "print ()\n",
    "print (' - and listing all branches')\n",
    "for name in iter_branch_names (): print (name)\n",
    "\n",
    "\n",
    "# 4TEST\n",
    "print ('Testing function: scan_dir()')\n",
    "print (' - listing all files in the working directory (excluding is_ignored files)')\n",
    "print (' - and checking, if they exists in the object database')\n",
    "\n",
    "file_path = Path ('.')\n",
    "for path, oid in scan_dir (file_path).items():\n",
    "    print (f'{data.object_exists (oid):2} : {path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
